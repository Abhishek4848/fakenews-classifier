{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalProject.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynNu0HZ7tB5I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "225ee5bf-4b3f-4210-8aa2-2054ee05a789"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "!ls \"/content/drive/My Drive/Project\"\n",
        "!pip install -U scikit-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "aftertrain.csv\t logregmodel.pkl  test.csv   train.csv\n",
            "corona_fake.csv  submit.csv\t  tfidf.pkl\n",
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/3a/eb8d7bbe28f4787d140bb9df685b7d5bf6115c0e2a969def4027144e98b6/scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 111kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.5)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.15.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.23.1 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6_8_7TWr4yP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "51600a46-67bb-4436-fe52-928ff672c7db"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.corpus import stopwords\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WPQ9OvXATNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(df):\n",
        "  ps= PorterStemmer()\n",
        "  stopWords = set(stopwords.words('english'))\n",
        "  train['pro']=' '\n",
        "  for i in range(len(df['full'])):\n",
        "    words = word_tokenize(df['full'][i])\n",
        "    stem=[]\n",
        "    for w in words:\n",
        "      if w not in stopWords:\n",
        "        stem.append(ps.stem(w))\n",
        "    df.loc[i,'pro']=' '.join(stem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNUm0rylw5cM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/Project/train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/Project/test.csv')\n",
        "corona=pd.read_csv('/content/drive/My Drive/Project/corona_fake.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghco14pKxHXM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "de858852-a8c7-4f40-b2e4-85763282af9b"
      },
      "source": [
        "print(train['label'])\n",
        "test['label']  = '2'\n",
        "test['label']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        1\n",
            "1        0\n",
            "2        1\n",
            "3        1\n",
            "4        1\n",
            "        ..\n",
            "20795    0\n",
            "20796    0\n",
            "20797    0\n",
            "20798    1\n",
            "20799    1\n",
            "Name: label, Length: 20800, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       2\n",
              "1       2\n",
              "2       2\n",
              "3       2\n",
              "4       2\n",
              "       ..\n",
              "5195    2\n",
              "5196    2\n",
              "5197    2\n",
              "5198    2\n",
              "5199    2\n",
              "Name: label, Length: 5200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f8vYFK-xuX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test=test.fillna(' ')\n",
        "train=train.fillna(' ')\n",
        "corona=corona.fillna(' ')\n",
        "test['full']=test['title']+' '+test['author']+test['text']\n",
        "train['full']=train['title']+' '+train['author']+train['text']\n",
        "corona['full']=corona['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAHB9JvKt9mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(corona['label'])):\n",
        "  if corona['label'][i] == \"Fake\":\n",
        "    corona['label'][i] = np.int64(1)\n",
        "  else:\n",
        "    corona['label'][i] = np.int64(0)\n",
        "\n",
        "corona_label=np.array(corona['label'],dtype='int')\n",
        "train_label=np.array(train['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00BdzUOLURM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocess(test)\n",
        "preprocess(corona)\n",
        "preprocess(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3Lq7fFi7cN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train['pro'][0])\n",
        "print(corona['pro'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8IRcppK0SxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train['pro'].values, train_label, random_state=0)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XTnv28EyYK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tfidf_vectorizer = TfidfVectorizer(analyzer='word',ngram_range=(1,3),max_df=0.5,smooth_idf=True,norm='l2')\n",
        "tfidf_vectorizer = TfidfVectorizer(analyzer='word', binary=False, decode_error='strict', encoding='utf-8',input='content', lowercase=True, max_df=0.5, max_features=None,min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,smooth_idf=True, stop_words=None, strip_accents=None,sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',tokenizer=None, use_idf=True, vocabulary=None)\n",
        "tfidf_train = tfidf_vectorizer.fit(train['pro'].values)\n",
        "tfidf_train_ans = train['label'].values\n",
        "tfidf_train = tfidf_vectorizer.transform(train['pro'].values)\n",
        "corona_train= tfidf_vectorizer.transform(corona['pro'].values)\n",
        "#tfidf_test = tfidf_vectorizer.fit_transform(test['full'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQpqooCnCnQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=tfidf_vectorizer.transform(X_train)\n",
        "X_test=tfidf_vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wJVDM6e0Wor",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0e350d38-7ce8-4e79-c1bd-9b399f3affdb"
      },
      "source": [
        "modelNB = MultinomialNB()   #NaiveBayes\n",
        "modelNB.fit(X_train, y_train)\n",
        "#print(modelNB.score(corona_train,corona_label))\n",
        "print('Accuracy of NaiveBayes classifier on training set: {:.2f}'.format(modelNB.score(X_train, y_train)))\n",
        "print('Accuracy of NaiveBayes classifier on test set: {:.2f}'.format(modelNB.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of NaiveBayes classifier on training set: 0.97\n",
            "Accuracy of NaiveBayes classifier on test set: 0.86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M1Smz5W0YXW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "eef6213b-9f37-4464-ccd8-7dbe0563b3b1"
      },
      "source": [
        "#logreg = LogisticRegression(max_iter=200,random_state=0)\n",
        "logreg=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,intercept_scaling=1, l1_ratio=None, max_iter=1000,multi_class='auto', n_jobs=None, penalty='l2',random_state=0, solver='lbfgs', tol=0.0001, verbose=0,warm_start=False)\n",
        "logreg.fit(X_train, y_train)\n",
        "print('Accuracy of LogisticRegress classifier on training set: {:.3f}'.format(logreg.score(X_train, y_train)))\n",
        "print('Accuracy of LogisticRegress classifier on test set: {:.3f}'.format(logreg.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of LogisticRegress classifier on training set: 0.991\n",
            "Accuracy of LogisticRegress classifier on test set: 0.954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqrKXX9m78CW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e580594-033d-4cf2-ea8d-cdc2e6267073"
      },
      "source": [
        "print('Accuracy of LogisticRegress classifier on COVID dataset : {:.3f}'.format(logreg.score(corona_train, corona_label)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of LogisticRegress classifier on COVID dataset: 0.419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t676vkPmCLj_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f88a5eb7-35a8-4fce-cc44-a835b88b6a6f"
      },
      "source": [
        "submit = pd.read_csv('/content/drive/My Drive/Project/submit.csv')\n",
        "tfdif2 = tfidf_vectorizer.transform(test['pro'].values)\n",
        "predictions = logreg.predict(tfdif2)\n",
        "pred = pd.DataFrame(predictions,columns=['label'])\n",
        "pred['id']=test['id']\n",
        "pred.groupby('label').count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2467</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id\n",
              "label      \n",
              "0      2733\n",
              "1      2467"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxEZWS8UErua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49fa4cda-a4fd-422d-f4f5-67b10c00c3f2"
      },
      "source": [
        "accuracy=(sum(pred['label'] == submit['label']))/(len(pred['label']))\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6388461538461538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnVfUwDzJ1uB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "236bc07e-1e4e-427a-d945-51379dac67ff"
      },
      "source": [
        "article=input(\"Enter article\")\n",
        "ps=PorterStemmer()\n",
        "stopWords = set(stopwords.words('english'))\n",
        "words = word_tokenize(article)\n",
        "stem=[]\n",
        "for w in words:\n",
        "  if w not in stopWords:\n",
        "    stem.append(ps.stem(w))\n",
        "finalart=' '.join(stem)\n",
        "final=[]\n",
        "final.append(finalart)\n",
        "print(final)\n",
        "test1=tfidf_vectorizer.transform(final)\n",
        "if logreg.predict(test1)==0:\n",
        "  print(\"News is reliable\")\n",
        "else:\n",
        "    print(\"News is unreliable\")\n",
        "#print(logreg.predict(test1))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter articleIndia-China Border Clash Updates: The Indian Army has said no personnel are “unaccounted for” following the Galwan clash on Monday night. Reports have suggested that 10 soldiers, including two Majors, were released on Thursday evening, three days after the violent scuffle with Chinese troops on the Ladakh border. However, there is no official word on the capture of Indian soldiers. India lost 20 soldiers in the clashes while a total of 76 personnel have received injuries to various degrees. Ten Indian soldiers were also taken captive by the Chinese Army who were released on Thursday, reported PTI. Tensions are simmering among the Army units stationed in Ladakh following the killings of 20 soldiers. Prime Minister Narendra Modi will be holding an all-party meeting this evening to brief the political parties on the Ladakh clash and the ongoing situation between India and China. The Modi government has come under heavy criticism for the deaths of 20 Indian soldiers at the hands of Chinese military. Follow live updates on the developments of India-China clash:\n",
            "['india-china border clash updat : the indian armi said personnel “ unaccount ” follow galwan clash monday night . report suggest 10 soldier , includ two major , releas thursday even , three day violent scuffl chines troop ladakh border . howev , offici word captur indian soldier . india lost 20 soldier clash total 76 personnel receiv injuri variou degre . ten indian soldier also taken captiv chines armi releas thursday , report pti . tension simmer among armi unit station ladakh follow kill 20 soldier . prime minist narendra modi hold all-parti meet even brief polit parti ladakh clash ongo situat india china . the modi govern come heavi critic death 20 indian soldier hand chines militari . follow live updat develop india-china clash :']\n",
            "News is reliable\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "89EXINg4Ev7k",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle.dump(tfidf_vectorizer,open('/content/drive/My Drive/Project/tfidf.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RoDNgxPQSGt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1fbb6f97-234a-4701-9f18-05fa7b19ac9f"
      },
      "source": [
        "import joblib \n",
        "  \n",
        "# Save the model as a pickle in a file \n",
        "joblib.dump(logreg, '/content/drive/My Drive/Project/logregmodel.pkl')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Project/logregmodel.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLrDav07Muk_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "14c65c54-60c5-4bff-87b9-66ea6bc9d47c"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(smooth_idf=True)),\n",
        "    ('clf', LogisticRegression()),\n",
        "])\n",
        "parameters = {\n",
        "    'clf__C':[0.001,0.009,0.01,.09,1,5,10,25]\n",
        "}\n",
        "\n",
        "grid_search_tune = GridSearchCV(pipeline, parameters)\n",
        "grid_search_tune.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters set:\")\n",
        "print(grid_search_tune.best_estimator_.steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best parameters set:\n",
            "[('tfidf', TfidfVectorizer()), ('clf', LogisticRegression(C=25))]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}